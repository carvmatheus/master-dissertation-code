{
  "timestamp": "2026-01-15T02:57:05.041570",
  "strategies": [
    "raw_gpt-oss-120b",
    "sliding_window_gpt-oss-120b",
    "parallel_window_gpt-oss-120b",
    "semantic_compression_gpt-oss-120b",
    "rig_gpt-oss-120b",
    "raw_gpt-oss-20b",
    "sliding_window_gpt-oss-20b",
    "parallel_window_gpt-oss-20b",
    "semantic_compression_gpt-oss-20b",
    "rig_gpt-oss-20b"
  ],
  "benchmarks": [
    "needle_in_haystack",
    "ruler",
    "longbench"
  ],
  "results": [
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_start_7392",
      "score": 1.0,
      "latency_ms": 568.8316250016214,
      "response": "7392",
      "expected": "7392",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4432,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_pos_0.25_7392",
      "score": 1.0,
      "latency_ms": 353.6697080126032,
      "response": "7392",
      "expected": "7392",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4287,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_middle_7392",
      "score": 1.0,
      "latency_ms": 370.7853750092909,
      "response": "7392",
      "expected": "7392",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4287,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_pos_0.75_7392",
      "score": 1.0,
      "latency_ms": 527.2045840101782,
      "response": "7392",
      "expected": "7392",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4267,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_end_7392",
      "score": 1.0,
      "latency_ms": 361.703626011149,
      "response": "7392",
      "expected": "7392",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4317,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_start_15 de març",
      "score": 1.0,
      "latency_ms": 438.89737500285264,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4282,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_pos_0.25_15 de març",
      "score": 1.0,
      "latency_ms": 1343.3794169977773,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4254,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_middle_15 de març",
      "score": 1.0,
      "latency_ms": 582.2667080065003,
      "response": "15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4381,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_pos_0.75_15 de març",
      "score": 1.0,
      "latency_ms": 437.49108399788383,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4328,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_end_15 de març",
      "score": 1.0,
      "latency_ms": 7539.572170004249,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4306,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_start_Operação F",
      "score": 1.0,
      "latency_ms": 6632.548002991825,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4299,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_pos_0.25_Operação F",
      "score": 1.0,
      "latency_ms": 7838.476461998653,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4291,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_middle_Operação F",
      "score": 1.0,
      "latency_ms": 6502.106127998559,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4277,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_pos_0.75_Operação F",
      "score": 1.0,
      "latency_ms": 7642.189670994412,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4334,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "needle_end_Operação F",
      "score": 1.0,
      "latency_ms": 8503.604003999499,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4364,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_start_7392",
      "score": 1.0,
      "latency_ms": 6564.343712001573,
      "response": "7392",
      "expected": "7392",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4230,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_pos_0.25_7392",
      "score": 0.0,
      "latency_ms": 7669.437461998314,
      "response": "Desculpe, não posso ajudar com isso.",
      "expected": "7392",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4305,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_middle_7392",
      "score": 0.0,
      "latency_ms": 7674.050169996917,
      "response": "Desculpe, não posso ajudar com isso.",
      "expected": "7392",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4334,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_pos_0.75_7392",
      "score": 1.0,
      "latency_ms": 8439.931586995954,
      "response": "7392",
      "expected": "7392",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4397,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_end_7392",
      "score": 1.0,
      "latency_ms": 7595.972919996711,
      "response": "7392",
      "expected": "7392",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4363,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_start_15 de març",
      "score": 1.0,
      "latency_ms": 7652.752462003264,
      "response": "15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4391,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_pos_0.25_15 de març",
      "score": 1.0,
      "latency_ms": 7636.1031710112,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4331,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_middle_15 de març",
      "score": 1.0,
      "latency_ms": 8817.442253988702,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4267,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_pos_0.75_15 de març",
      "score": 1.0,
      "latency_ms": 7597.762211997178,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4196,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_end_15 de març",
      "score": 1.0,
      "latency_ms": 7689.215878010145,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4167,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_start_Operação F",
      "score": 1.0,
      "latency_ms": 7515.32871100062,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4338,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_pos_0.25_Operação F",
      "score": 1.0,
      "latency_ms": 7525.957628007745,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4312,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_middle_Operação F",
      "score": 1.0,
      "latency_ms": 7691.6974199994,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4130,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_pos_0.75_Operação F",
      "score": 1.0,
      "latency_ms": 7491.856252992875,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4282,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "needle_end_Operação F",
      "score": 1.0,
      "latency_ms": 7663.41154499969,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4166,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_start_7392",
      "score": 1.0,
      "latency_ms": 7903.653504006797,
      "response": "7392",
      "expected": "7392",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4247,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_pos_0.25_7392",
      "score": 1.0,
      "latency_ms": 5454.776169004617,
      "response": "7392",
      "expected": "7392",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4248,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_middle_7392",
      "score": 1.0,
      "latency_ms": 7612.126502994215,
      "response": "7392",
      "expected": "7392",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4434,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_pos_0.75_7392",
      "score": 1.0,
      "latency_ms": 6456.714002997614,
      "response": "7392",
      "expected": "7392",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4275,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_end_7392",
      "score": 1.0,
      "latency_ms": 7547.5112949934555,
      "response": "7392",
      "expected": "7392",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4229,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_start_15 de març",
      "score": 1.0,
      "latency_ms": 6598.301878009806,
      "response": "A reunião foi remarcada para 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4140,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_pos_0.25_15 de març",
      "score": 1.0,
      "latency_ms": 7708.891628004494,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4311,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_middle_15 de març",
      "score": 1.0,
      "latency_ms": 7640.258837011061,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4179,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_pos_0.75_15 de març",
      "score": 1.0,
      "latency_ms": 8284.17167000589,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4274,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_end_15 de març",
      "score": 1.0,
      "latency_ms": 7145.127420008066,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4422,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_start_Operação F",
      "score": 1.0,
      "latency_ms": 6567.9058370005805,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4307,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_pos_0.25_Operação F",
      "score": 1.0,
      "latency_ms": 7588.634337007534,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4106,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_middle_Operação F",
      "score": 1.0,
      "latency_ms": 6542.330793992733,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4341,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_pos_0.75_Operação F",
      "score": 1.0,
      "latency_ms": 7612.135962001048,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4384,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "needle_end_Operação F",
      "score": 1.0,
      "latency_ms": 6812.482460998581,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4127,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_start_7392",
      "score": 1.0,
      "latency_ms": 13284.244713999215,
      "response": "7392",
      "expected": "7392",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4296,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_pos_0.25_7392",
      "score": 1.0,
      "latency_ms": 19011.32459100336,
      "response": "7392",
      "expected": "7392",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4214,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_middle_7392",
      "score": 1.0,
      "latency_ms": 10997.754088995862,
      "response": "7392",
      "expected": "7392",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4264,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_pos_0.75_7392",
      "score": 1.0,
      "latency_ms": 16893.266882005264,
      "response": "7392",
      "expected": "7392",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4322,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_end_7392",
      "score": 1.0,
      "latency_ms": 15702.841674006777,
      "response": "7392",
      "expected": "7392",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4221,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_start_15 de març",
      "score": 1.0,
      "latency_ms": 17643.334674008656,
      "response": "15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4148,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_pos_0.25_15 de març",
      "score": 1.0,
      "latency_ms": 18719.92846801004,
      "response": "15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4291,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_middle_15 de març",
      "score": 1.0,
      "latency_ms": 15264.276547997724,
      "response": "15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4252,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_pos_0.75_15 de març",
      "score": 1.0,
      "latency_ms": 18764.80896701105,
      "response": "15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4385,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_end_15 de març",
      "score": 1.0,
      "latency_ms": 12706.72513100726,
      "response": "15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4249,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_start_Operação F",
      "score": 1.0,
      "latency_ms": 15442.291424013092,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4155,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_pos_0.25_Operação F",
      "score": 1.0,
      "latency_ms": 14739.87879899505,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4292,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_middle_Operação F",
      "score": 1.0,
      "latency_ms": 25331.34876099939,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4355,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_pos_0.75_Operação F",
      "score": 1.0,
      "latency_ms": 16100.17009099829,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4266,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "needle_end_Operação F",
      "score": 1.0,
      "latency_ms": 15438.830881990725,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4232,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_start_7392",
      "score": 1.0,
      "latency_ms": 7191.247711991309,
      "response": "7392",
      "expected": "7392",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4258,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_pos_0.25_7392",
      "score": 1.0,
      "latency_ms": 7100.532252996345,
      "response": "7392",
      "expected": "7392",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4270,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_middle_7392",
      "score": 1.0,
      "latency_ms": 7086.554003006313,
      "response": "7392",
      "expected": "7392",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4415,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_pos_0.75_7392",
      "score": 1.0,
      "latency_ms": 6800.298543996178,
      "response": "7392",
      "expected": "7392",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4511,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_end_7392",
      "score": 1.0,
      "latency_ms": 7704.292420006823,
      "response": "7392",
      "expected": "7392",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4249,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_start_15 de març",
      "score": 0.8,
      "latency_ms": 6742.843294006889,
      "response": "A reunião foi remarcada para 15 de março, às 14 h.",
      "expected": "15 de março às 14h",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4210,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_pos_0.25_15 de març",
      "score": 1.0,
      "latency_ms": 7825.82421200641,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4114,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_middle_15 de març",
      "score": 1.0,
      "latency_ms": 6911.265543996706,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4316,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_pos_0.75_15 de març",
      "score": 1.0,
      "latency_ms": 7824.426628998481,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4290,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_end_15 de març",
      "score": 1.0,
      "latency_ms": 6846.6460869967705,
      "response": "A reunião foi remarcada para o dia 15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4358,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_start_Operação F",
      "score": 1.0,
      "latency_ms": 8108.695254006307,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4318,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_pos_0.25_Operação F",
      "score": 1.0,
      "latency_ms": 6780.337378004333,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4180,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_middle_Operação F",
      "score": 1.0,
      "latency_ms": 6777.787794999313,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4344,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_pos_0.75_Operação F",
      "score": 1.0,
      "latency_ms": 7632.751087003271,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4248,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "needle_end_Operação F",
      "score": 1.0,
      "latency_ms": 6743.946712012985,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4182,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_start_7392",
      "score": 1.0,
      "latency_ms": 358.52254199562594,
      "response": "7392",
      "expected": "7392",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4399,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_pos_0.25_7392",
      "score": 1.0,
      "latency_ms": 310.0425829907181,
      "response": "7392",
      "expected": "7392",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4166,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_middle_7392",
      "score": 1.0,
      "latency_ms": 308.15604199597146,
      "response": "7392",
      "expected": "7392",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4252,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_pos_0.75_7392",
      "score": 1.0,
      "latency_ms": 366.9377909973264,
      "response": "7392",
      "expected": "7392",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4340,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_end_7392",
      "score": 1.0,
      "latency_ms": 337.67520799301565,
      "response": "7392",
      "expected": "7392",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4219,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_start_15 de març",
      "score": 1.0,
      "latency_ms": 296.80254199774936,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4295,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_pos_0.25_15 de març",
      "score": 1.0,
      "latency_ms": 302.2997509979177,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4363,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_middle_15 de març",
      "score": 1.0,
      "latency_ms": 305.6504580017645,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4314,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_pos_0.75_15 de març",
      "score": 1.0,
      "latency_ms": 2444.523375001154,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4214,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_end_15 de març",
      "score": 1.0,
      "latency_ms": 6390.566002999549,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4335,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_start_Operação F",
      "score": 1.0,
      "latency_ms": 7395.206629007589,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4377,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_pos_0.25_Operação F",
      "score": 1.0,
      "latency_ms": 7482.478086996707,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4336,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_middle_Operação F",
      "score": 1.0,
      "latency_ms": 6585.400127994944,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4238,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_pos_0.75_Operação F",
      "score": 1.0,
      "latency_ms": 7385.905877992627,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4310,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "needle_end_Operação F",
      "score": 1.0,
      "latency_ms": 6756.410920002963,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4378,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_start_7392",
      "score": 1.0,
      "latency_ms": 7611.9893369905185,
      "response": "7392",
      "expected": "7392",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4374,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_pos_0.25_7392",
      "score": 1.0,
      "latency_ms": 7521.632545001921,
      "response": "7392",
      "expected": "7392",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4141,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_middle_7392",
      "score": 1.0,
      "latency_ms": 7409.805128001608,
      "response": "7392",
      "expected": "7392",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4221,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_pos_0.75_7392",
      "score": 1.0,
      "latency_ms": 7452.026377999573,
      "response": "7392",
      "expected": "7392",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4378,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_end_7392",
      "score": 1.0,
      "latency_ms": 7592.327211998054,
      "response": "7392",
      "expected": "7392",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4271,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_start_15 de març",
      "score": 1.0,
      "latency_ms": 7504.799337009899,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4262,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_pos_0.25_15 de març",
      "score": 1.0,
      "latency_ms": 8428.398253992782,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4362,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_middle_15 de març",
      "score": 1.0,
      "latency_ms": 7600.323295002454,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4197,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_pos_0.75_15 de març",
      "score": 1.0,
      "latency_ms": 7574.264545008191,
      "response": "15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4416,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_end_15 de març",
      "score": 1.0,
      "latency_ms": 7392.002795008011,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4400,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_start_Operação F",
      "score": 1.0,
      "latency_ms": 7457.614752987865,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4206,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_pos_0.25_Operação F",
      "score": 1.0,
      "latency_ms": 7415.6786289968295,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4226,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_middle_Operação F",
      "score": 1.0,
      "latency_ms": 7397.150461998535,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4265,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_pos_0.75_Operação F",
      "score": 1.0,
      "latency_ms": 7484.833045004052,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4234,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "needle_end_Operação F",
      "score": 1.0,
      "latency_ms": 7399.999461005791,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4303,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_start_7392",
      "score": 1.0,
      "latency_ms": 7468.1688790005865,
      "response": "7392",
      "expected": "7392",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4262,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_pos_0.25_7392",
      "score": 1.0,
      "latency_ms": 6656.844461002038,
      "response": "7392",
      "expected": "7392",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4312,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_middle_7392",
      "score": 1.0,
      "latency_ms": 7420.528211994679,
      "response": "7392",
      "expected": "7392",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4187,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_pos_0.75_7392",
      "score": 1.0,
      "latency_ms": 6605.632795006386,
      "response": "7392",
      "expected": "7392",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4329,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_end_7392",
      "score": 1.0,
      "latency_ms": 7519.502212002408,
      "response": "7392",
      "expected": "7392",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4244,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_start_15 de març",
      "score": 1.0,
      "latency_ms": 7402.210211992497,
      "response": "15 de março, às 14h.",
      "expected": "15 de março às 14h",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4207,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_pos_0.25_15 de març",
      "score": 1.0,
      "latency_ms": 7463.384086993756,
      "response": "Para o dia **15 de março às 14h**.",
      "expected": "15 de março às 14h",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4250,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_middle_15 de març",
      "score": 1.0,
      "latency_ms": 7412.033795000752,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4405,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_pos_0.75_15 de març",
      "score": 1.0,
      "latency_ms": 6554.050336999353,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4327,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_end_15 de març",
      "score": 1.0,
      "latency_ms": 7434.848962002434,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4310,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_start_Operação F",
      "score": 1.0,
      "latency_ms": 6418.803545006085,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4296,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_pos_0.25_Operação F",
      "score": 1.0,
      "latency_ms": 7390.8022940013325,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4320,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_middle_Operação F",
      "score": 1.0,
      "latency_ms": 6612.87354498927,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4218,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_pos_0.75_Operação F",
      "score": 1.0,
      "latency_ms": 7423.813296001754,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4285,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "needle_end_Operação F",
      "score": 1.0,
      "latency_ms": 7482.456628000364,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4255,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_start_7392",
      "score": 1.0,
      "latency_ms": 18787.46396698989,
      "response": "7392",
      "expected": "7392",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4338,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_pos_0.25_7392",
      "score": 0.0,
      "latency_ms": 13914.211923009134,
      "response": "Desculpe, mas não posso ajudar com isso.",
      "expected": "7392",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4309,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_middle_7392",
      "score": 1.0,
      "latency_ms": 12409.0488810034,
      "response": "7392",
      "expected": "7392",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4306,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_pos_0.75_7392",
      "score": 0.0,
      "latency_ms": 13767.227257005288,
      "response": "I’m sorry, but I can’t help with that.",
      "expected": "7392",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4389,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_end_7392",
      "score": 1.0,
      "latency_ms": 14164.500505998149,
      "response": "7392",
      "expected": "7392",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4237,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_start_15 de març",
      "score": 1.0,
      "latency_ms": 14816.528631999972,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4294,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_pos_0.25_15 de març",
      "score": 1.0,
      "latency_ms": 13740.509215000202,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4243,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_middle_15 de març",
      "score": 1.0,
      "latency_ms": 13739.026715004002,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4312,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_pos_0.75_15 de març",
      "score": 0.0,
      "latency_ms": 12592.762505999417,
      "response": "Não há informação no contexto sobre a data da reunião remarcada.",
      "expected": "15 de março às 14h",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4185,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_end_15 de març",
      "score": 1.0,
      "latency_ms": 13645.834214999923,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4281,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_start_Operação F",
      "score": 1.0,
      "latency_ms": 14308.180715001072,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4414,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_pos_0.25_Operação F",
      "score": 1.0,
      "latency_ms": 13987.232422994566,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4342,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_middle_Operação F",
      "score": 1.0,
      "latency_ms": 14808.038631992531,
      "response": "Operação Fênix",
      "expected": "Operação Fênix",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4391,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_pos_0.75_Operação F",
      "score": 1.0,
      "latency_ms": 19434.41867599904,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4238,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "needle_end_Operação F",
      "score": 1.0,
      "latency_ms": 13594.678338995436,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4320,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_start_7392",
      "score": 1.0,
      "latency_ms": 7419.482544995844,
      "response": "7392",
      "expected": "7392",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4316,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_pos_0.25_7392",
      "score": 1.0,
      "latency_ms": 6586.942586000077,
      "response": "7392",
      "expected": "7392",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4221,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_middle_7392",
      "score": 1.0,
      "latency_ms": 6654.836378002074,
      "response": "7392",
      "expected": "7392",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4295,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_pos_0.75_7392",
      "score": 1.0,
      "latency_ms": 7737.825962001807,
      "response": "7392",
      "expected": "7392",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4288,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_end_7392",
      "score": 1.0,
      "latency_ms": 7874.677211992093,
      "response": "7392",
      "expected": "7392",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4245,
      "needle_fact": "O código secreto para acessar o cofre é 7392."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_start_15 de març",
      "score": 1.0,
      "latency_ms": 6613.504711000132,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4226,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_pos_0.25_15 de març",
      "score": 1.0,
      "latency_ms": 6607.448212002055,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4196,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_middle_15 de març",
      "score": 1.0,
      "latency_ms": 7701.313002995448,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4236,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_pos_0.75_15 de març",
      "score": 1.0,
      "latency_ms": 6595.687043998623,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4144,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_end_15 de març",
      "score": 1.0,
      "latency_ms": 6629.877670013229,
      "response": "15 de março às 14h.",
      "expected": "15 de março às 14h",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4334,
      "needle_fact": "A reunião foi remarcada para o dia 15 de março às 14h."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_start_Operação F",
      "score": 1.0,
      "latency_ms": 7713.687711991952,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "start",
      "num_paragraphs": 20,
      "context_chars": 4217,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_pos_0.25_Operação F",
      "score": 1.0,
      "latency_ms": 6608.958753000479,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.25,
      "num_paragraphs": 20,
      "context_chars": 4231,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_middle_Operação F",
      "score": 1.0,
      "latency_ms": 6667.267419004929,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "middle",
      "num_paragraphs": 20,
      "context_chars": 4336,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_pos_0.75_Operação F",
      "score": 1.0,
      "latency_ms": 7687.91808700189,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": 0.75,
      "num_paragraphs": 20,
      "context_chars": 4279,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "needle_in_haystack",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "needle_end_Operação F",
      "score": 1.0,
      "latency_ms": 6659.773585997755,
      "response": "Operação Fênix.",
      "expected": "Operação Fênix",
      "position": "end",
      "num_paragraphs": 20,
      "context_chars": 4146,
      "needle_fact": "O nome do projeto secreto é Operação Fênix."
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 432.50537500716746,
      "response": "90,69.",
      "expected": "90.69",
      "context_size": 10,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 740
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 298.66495900205337,
      "response": "A chave de acesso para o sistema 2 é **KEY-4611-BETA**.",
      "expected": "KEY-4611-BETA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 740
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 300.17341699567623,
      "response": "O valor do parâmetro 3 é **36.00**.",
      "expected": "36.00",
      "context_size": 10,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 740
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 387.7634160016896,
      "response": "KEY-9785-ALPHA",
      "expected": "KEY-9785-ALPHA",
      "context_size": 10,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 742
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 392.16662500984967,
      "response": "KEY-2291-GAMMA",
      "expected": "KEY-2291-GAMMA",
      "context_size": 10,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 742
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 310.71004099794663,
      "response": "A chave de acesso para o sistema 3 é **KEY-6925-GAMMA**.",
      "expected": "KEY-6925-GAMMA",
      "context_size": 10,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 742
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 383.05037599639036,
      "response": "KEY-2169-GAMMA",
      "expected": "KEY-2169-GAMMA",
      "context_size": 10,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 712
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 275.1676670013694,
      "response": "22.68",
      "expected": "22.68",
      "context_size": 10,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 712
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 302.04941699048504,
      "response": "O valor do parâmetro 3 é **32,20**.",
      "expected": "32.20",
      "context_size": 10,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 712
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 294.98291699565016,
      "response": "O valor do parâmetro 1 é **64,50**.",
      "expected": "64.50",
      "context_size": 10,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 715
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 297.98229099833407,
      "response": "O valor do parâmetro 2 é **59,18**.",
      "expected": "59.18",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 715
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 455.3189169964753,
      "response": "KEY-3287-ALPHA",
      "expected": "KEY-3287-ALPHA",
      "context_size": 10,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 715
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 357.3902089992771,
      "response": "KEY-3646-GAMMA",
      "expected": "KEY-3646-GAMMA",
      "context_size": 25,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 1625
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 376.21966599544976,
      "response": "O valor do parâmetro 2 é **1,76**.",
      "expected": "1.76",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 1625
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 400.8289580087876,
      "response": "KEY-9005-ALPHA",
      "expected": "KEY-9005-ALPHA",
      "context_size": 25,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 1625
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 402.49637499800883,
      "response": "KEY-2160-GAMMA",
      "expected": "KEY-2160-GAMMA",
      "context_size": 25,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 1627
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 358.71058399789035,
      "response": "ID-46500",
      "expected": "ID-46500",
      "context_size": 25,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 1627
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 412.52199999871664,
      "response": "O valor do parâmetro 3 é **63,27**.",
      "expected": "63.27",
      "context_size": 25,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 1627
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 353.0742089933483,
      "response": "KEY-1960-ALPHA",
      "expected": "KEY-1960-ALPHA",
      "context_size": 25,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 1026.0974590055412,
      "response": "KEY-1035-BETA",
      "expected": "KEY-1035-BETA",
      "context_size": 25,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 356.68966700905,
      "response": "KEY-8454-BETA",
      "expected": "KEY-8454-BETA",
      "context_size": 25,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 360.97433300164994,
      "response": "ID-11220",
      "expected": "ID-11220",
      "context_size": 25,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 1618
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 4383.245377001003,
      "response": "A chave de acesso para o sistema 2 é **KEY-2638-ALPHA**.",
      "expected": "KEY-2638-ALPHA",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 1618
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 4628.140834000078,
      "response": "O valor do parâmetro 3 é **28,64**.",
      "expected": "28.64",
      "context_size": 25,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 1618
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 5536.435086003621,
      "response": "O valor do parâmetro 1 é **14,48**.",
      "expected": "14.48",
      "context_size": 50,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 3115
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 6752.461919997586,
      "response": "ID-71694",
      "expected": "ID-71694",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 3115
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 6490.068045008229,
      "response": "ID-36158",
      "expected": "ID-36158",
      "context_size": 50,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 3115
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 573.9113750023535,
      "response": "O valor do parâmetro 1 é **99,09**.",
      "expected": "99.09",
      "context_size": 50,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 2985
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 6475.334503003978,
      "response": "KEY-7790-GAMMA",
      "expected": "KEY-7790-GAMMA",
      "context_size": 50,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 2985
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 6460.050794004928,
      "response": "O valor do parâmetro 3 é **25,91**.",
      "expected": "25.91",
      "context_size": 50,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 2985
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 6585.326419008197,
      "response": "A chave de acesso para o sistema 1 é **KEY-3091-GAMMA**.",
      "expected": "KEY-3091-GAMMA",
      "context_size": 50,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 3011
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 6642.166211997392,
      "response": "O valor do parâmetro 2 é **4,50**.",
      "expected": "4.50",
      "context_size": 50,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 3011
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 641.1836670013145,
      "response": "O valor do parâmetro 3 é **73,84**.",
      "expected": "73.84",
      "context_size": 50,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 3011
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 6539.6541290101595,
      "response": "ID-46559",
      "expected": "ID-46559",
      "context_size": 50,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 3043
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 6480.615210995893,
      "response": "A chave de acesso para o sistema 2 é **KEY-4995-BETA**.",
      "expected": "KEY-4995-BETA",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 3043
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 6464.784669995424,
      "response": "O valor do parâmetro 3 é **79,85**.",
      "expected": "79.85",
      "context_size": 50,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 3043
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 2553.434417990502,
      "response": "ID-63271",
      "expected": "ID-63271",
      "context_size": 10,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 717
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 2773.3271259930916,
      "response": "KEY-4937-GAMMA",
      "expected": "KEY-4937-GAMMA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 717
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 502.5642089894973,
      "response": "KEY-9041-BETA",
      "expected": "KEY-9041-BETA",
      "context_size": 10,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 717
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 2350.485917995684,
      "response": "O valor do parâmetro 1 é **25,40**.",
      "expected": "25.40",
      "context_size": 10,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 698
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 3485.3951270051766,
      "response": "ID-80236",
      "expected": "ID-80236",
      "context_size": 10,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 698
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 2597.0853340113536,
      "response": "O valor do parâmetro 3 é **24,24**.",
      "expected": "24.24",
      "context_size": 10,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 698
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 358.0325829971116,
      "response": "KEY-3068-GAMMA",
      "expected": "KEY-3068-GAMMA",
      "context_size": 10,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 756
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 2474.0463350026403,
      "response": "KEY-2680-ALPHA",
      "expected": "KEY-2680-ALPHA",
      "context_size": 10,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 756
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 2472.268666999298,
      "response": "O valor do parâmetro 3 é **37,60**.",
      "expected": "37.60",
      "context_size": 10,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 756
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 2420.3319170046598,
      "response": "98,53.",
      "expected": "98.53",
      "context_size": 10,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 738
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 3503.218793994165,
      "response": "77.79",
      "expected": "77.79",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 738
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 2441.7700429912657,
      "response": "ID-78494",
      "expected": "ID-78494",
      "context_size": 10,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 738
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 4391.07329401304,
      "response": "ID-31747",
      "expected": "ID-31747",
      "context_size": 25,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 1603
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 3849.453668008209,
      "response": "KEY-5728-BETA",
      "expected": "KEY-5728-BETA",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 1603
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 2625.669626999297,
      "response": "ID-71433",
      "expected": "ID-71433",
      "context_size": 25,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 1603
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 3481.317042998853,
      "response": "O valor do parâmetro 1 é **52,97**.",
      "expected": "52.97",
      "context_size": 25,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 1604
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 3427.120834996458,
      "response": "5.58",
      "expected": "5.58",
      "context_size": 25,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 1604
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 2351.644166992628,
      "response": "O identificador único do registro 3 é **ID-51224**.",
      "expected": "ID-51224",
      "context_size": 25,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 1604
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 3536.732334003318,
      "response": "KEY-8736-ALPHA",
      "expected": "KEY-8736-ALPHA",
      "context_size": 25,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 1637
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 4493.518253002549,
      "response": "KEY-3369-BETA",
      "expected": "KEY-3369-BETA",
      "context_size": 25,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 1637
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 2425.6996670010267,
      "response": "ID-88561",
      "expected": "ID-88561",
      "context_size": 25,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 1637
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 3348.862459999509,
      "response": "O valor do parâmetro 1 é **19.52**.",
      "expected": "19.52",
      "context_size": 25,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 1578
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 4585.87925300526,
      "response": "O valor do parâmetro 2 é **20,09**.",
      "expected": "20.09",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 1578
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 3854.4090439972933,
      "response": "A chave de acesso para o sistema 3 é **KEY-5342-BETA**.",
      "expected": "KEY-5342-BETA",
      "context_size": 25,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 1578
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 6425.726253000903,
      "response": "ID-89569",
      "expected": "ID-89569",
      "context_size": 50,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 3035
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 5586.036836000858,
      "response": "KEY-4588-GAMMA",
      "expected": "KEY-4588-GAMMA",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 3035
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 6470.196337002562,
      "response": "ID-91381",
      "expected": "ID-91381",
      "context_size": 50,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 3035
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 6459.822003002046,
      "response": "KEY-8285-ALPHA",
      "expected": "KEY-8285-ALPHA",
      "context_size": 50,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 3032
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 6476.223128003767,
      "response": "KEY-2627-GAMMA",
      "expected": "KEY-2627-GAMMA",
      "context_size": 50,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 3032
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 6609.272711997619,
      "response": "A chave de acesso para o sistema 3 é **KEY-9920-GAMMA**.",
      "expected": "KEY-9920-GAMMA",
      "context_size": 50,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 3032
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 6451.800502996775,
      "response": "A chave de acesso para o sistema 1 é **KEY-2557-BETA**.",
      "expected": "KEY-2557-BETA",
      "context_size": 50,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 3073
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 6729.4627530063735,
      "response": "A chave de acesso para o sistema 2 é **KEY-6120-GAMMA**.",
      "expected": "KEY-6120-GAMMA",
      "context_size": 50,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 3073
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 6571.32479500433,
      "response": "A chave de acesso para o sistema 3 é **KEY-7132-ALPHA**.",
      "expected": "KEY-7132-ALPHA",
      "context_size": 50,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 3073
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 359.14320799929556,
      "response": "O valor do parâmetro 1 é **40,05**.",
      "expected": "40.05",
      "context_size": 50,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 3057
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 6618.398877995787,
      "response": "ID-61807",
      "expected": "ID-61807",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 3057
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 5525.431336005568,
      "response": "O valor do parâmetro 3 foi configurado como **8.00**.",
      "expected": "8.00",
      "context_size": 50,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 3057
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 3580.19108499866,
      "response": "KEY-1693-BETA",
      "expected": "KEY-1693-BETA",
      "context_size": 10,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 718
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 2456.7457509983797,
      "response": "ID-70260",
      "expected": "ID-70260",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 718
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 2485.6628339912277,
      "response": "ID-51033",
      "expected": "ID-51033",
      "context_size": 10,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 718
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 347.963834006805,
      "response": "KEY-7560-GAMMA",
      "expected": "KEY-7560-GAMMA",
      "context_size": 10,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 714
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 2464.199626003392,
      "response": "ID-61873",
      "expected": "ID-61873",
      "context_size": 10,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 714
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 2437.1246679947944,
      "response": "KEY-6562-ALPHA",
      "expected": "KEY-6562-ALPHA",
      "context_size": 10,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 714
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 3417.75333500118,
      "response": "10.22",
      "expected": "10.22",
      "context_size": 10,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 763
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 2467.696584004443,
      "response": "O valor do parâmetro 2 é **64,59**.",
      "expected": "64.59",
      "context_size": 10,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 763
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 2372.5047089974396,
      "response": "O valor do parâmetro 3 é **98,74**.",
      "expected": "98.74",
      "context_size": 10,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 763
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 2462.267000999418,
      "response": "ID-17456",
      "expected": "ID-17456",
      "context_size": 10,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 722
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 2485.710918001132,
      "response": "A chave de acesso para o sistema 2 é **KEY-5703-ALPHA**.",
      "expected": "KEY-5703-ALPHA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 722
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 2404.802335004206,
      "response": "12.78",
      "expected": "12.78",
      "context_size": 10,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 722
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 4660.664084993186,
      "response": "KEY-6082-GAMMA",
      "expected": "KEY-6082-GAMMA",
      "context_size": 25,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 1617
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 3452.106377008022,
      "response": "O valor do parâmetro 2 é **85,50**.",
      "expected": "85.50",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 1617
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 4397.67704399128,
      "response": "ID-87993",
      "expected": "ID-87993",
      "context_size": 25,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 1617
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 3433.5968350060284,
      "response": "KEY-8355-ALPHA",
      "expected": "KEY-8355-ALPHA",
      "context_size": 25,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 1612
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 4431.486086003133,
      "response": "O valor do parâmetro 2 é **31,39**.",
      "expected": "31.39",
      "context_size": 25,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 1612
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 4483.7897940014955,
      "response": "KEY-4178-BETA",
      "expected": "KEY-4178-BETA",
      "context_size": 25,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 1612
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 3505.5649189889664,
      "response": "ID-51770",
      "expected": "ID-51770",
      "context_size": 25,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 4381.660793005722,
      "response": "ID-95191",
      "expected": "ID-95191",
      "context_size": 25,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 3531.607292999979,
      "response": "A chave de acesso para o sistema 3 é **KEY-3392-ALPHA**.",
      "expected": "KEY-3392-ALPHA",
      "context_size": 25,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 2550.98650099535,
      "response": "KEY-1713-GAMMA",
      "expected": "KEY-1713-GAMMA",
      "context_size": 25,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 1624
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 3369.3187099997886,
      "response": "A chave de acesso para o sistema 2 é **KEY-7116-BETA**.",
      "expected": "KEY-7116-BETA",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 1624
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 4369.11421098921,
      "response": "O valor do parâmetro 3 é **3,45**.",
      "expected": "3.45",
      "context_size": 25,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 1624
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 6827.108628000133,
      "response": "87,56.",
      "expected": "87.56",
      "context_size": 50,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 3040
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 5593.25750201242,
      "response": "ID-26545",
      "expected": "ID-26545",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 3040
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 6553.346502012573,
      "response": "ID-40932",
      "expected": "ID-40932",
      "context_size": 50,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 3040
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 6502.522128008422,
      "response": "ID-66704",
      "expected": "ID-66704",
      "context_size": 50,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 3065
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 5425.724710992654,
      "response": "8,15",
      "expected": "8.15",
      "context_size": 50,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 3065
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 6497.6245449943235,
      "response": "O valor do parâmetro 3 é **20,38**.",
      "expected": "20.38",
      "context_size": 50,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 3065
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 6452.27646100102,
      "response": "ID-38199",
      "expected": "ID-38199",
      "context_size": 50,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 3047
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 6438.198378004017,
      "response": "O valor do parâmetro 2 é **46,06**.",
      "expected": "46.06",
      "context_size": 50,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 3047
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 6796.212795001338,
      "response": "ID-46877",
      "expected": "ID-46877",
      "context_size": 50,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 3047
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 389.69820899365004,
      "response": "O valor do parâmetro 1 é **100,78**.",
      "expected": "100.78",
      "context_size": 50,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 3045
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 6461.23454500048,
      "response": "A chave de acesso para o sistema 2 é **KEY-2020-GAMMA**.",
      "expected": "KEY-2020-GAMMA",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 3045
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 6487.630670002545,
      "response": "ID-77984",
      "expected": "ID-77984",
      "context_size": 50,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 3045
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 7559.887586001423,
      "response": "39.28",
      "expected": "39.28",
      "context_size": 10,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 703
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 7272.23446201242,
      "response": "KEY-5735-GAMMA",
      "expected": "KEY-5735-GAMMA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 703
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 6273.9730030007195,
      "response": "ID-74094",
      "expected": "ID-74094",
      "context_size": 10,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 703
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 7863.8503789989045,
      "response": "KEY-5201-GAMMA",
      "expected": "KEY-5201-GAMMA",
      "context_size": 10,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 734
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact2",
      "score": 0.5,
      "latency_ms": 8927.148753005895,
      "response": "A chave de acesso para o sistema 2 é **KEY-4505‑ALPHA**.",
      "expected": "KEY-4505-ALPHA",
      "context_size": 10,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 734
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 7669.423128012568,
      "response": "35,71.",
      "expected": "35.71",
      "context_size": 10,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 734
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 5251.60016900918,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 223. Please try again in 1m36.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "21.52",
      "context_size": 10,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 734
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 74.10966699535493,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 245. Please try again in 1m45.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "61.61",
      "context_size": 10,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 734
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 170.2320000040345,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 245. Please try again in 1m45.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "26.96",
      "context_size": 10,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 734
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 69.74000000627711,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199999, Requested 247. Please try again in 1m46.271999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-4052-GAMMA",
      "context_size": 10,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 768
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 77.09420799801592,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199999, Requested 247. Please try again in 1m46.271999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1613-ALPHA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 768
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 81.8866670015268,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199999, Requested 247. Please try again in 1m46.271999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-2758-BETA",
      "context_size": 10,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 768
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 86.33637501043268,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199999, Requested 245. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "93.73",
      "context_size": 25,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 1572
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 136.47250000212807,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199999, Requested 246. Please try again in 1m45.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-44282",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 1572
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact3",
      "score": 0.0,
      "latency_ms": 75.88224999199156,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199998, Requested 245. Please try again in 1m44.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "47.88",
      "context_size": 25,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 1572
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 70.32662500569131,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199998, Requested 246. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-69432",
      "context_size": 25,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 1580
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 69.5133330009412,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199998, Requested 246. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-77272",
      "context_size": 25,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 1580
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 74.98608400055673,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199998, Requested 247. Please try again in 1m45.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-8484-GAMMA",
      "context_size": 25,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 1580
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 86.83095799642615,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199998, Requested 246. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-10455",
      "context_size": 25,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 1642
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 144.59741600148845,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 246. Please try again in 1m44.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-49107",
      "context_size": 25,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 1642
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 74.03966700076126,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 247. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-9920-BETA",
      "context_size": 25,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 1642
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 107.8410000045551,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 247. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "55.71",
      "context_size": 25,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 1622
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 80.90012500179,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 249. Please try again in 1m46.271999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1768-BETA",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 1622
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 73.84224999987055,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 247. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "86.48",
      "context_size": 25,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 1622
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 187.76004199753515,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199996, Requested 246. Please try again in 1m44.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-75444",
      "context_size": 50,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 2980
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 95.06679201149382,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199996, Requested 245. Please try again in 1m44.112s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "84.87",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 2980
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact3",
      "score": 0.0,
      "latency_ms": 73.58379200741183,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199996, Requested 247. Please try again in 1m44.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-5216-BETA",
      "context_size": 50,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 2980
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 101.59049999492709,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199995, Requested 246. Please try again in 1m44.112s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-99709",
      "context_size": 50,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 3081
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 72.78854200558271,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199995, Requested 247. Please try again in 1m44.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-9897-GAMMA",
      "context_size": 50,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 3081
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 77.73658400401473,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199995, Requested 245. Please try again in 1m43.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "5.22",
      "context_size": 50,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 3081
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 1401.3876679964596,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199992, Requested 246. Please try again in 1m42.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-45247",
      "context_size": 50,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 3011
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 81.90066699171439,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199992, Requested 247. Please try again in 1m43.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-5397-BETA",
      "context_size": 50,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 3011
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 74.33799999125767,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199992, Requested 246. Please try again in 1m42.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-18292",
      "context_size": 50,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 3011
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 164.46483301115222,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199991, Requested 247. Please try again in 1m42.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-8052-ALPHA",
      "context_size": 50,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 2974
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 92.77470801316667,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199991, Requested 246. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-22924",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 2974
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 79.48891699197702,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199991, Requested 247. Please try again in 1m42.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-4637-GAMMA",
      "context_size": 50,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 2974
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 530.9128340013558,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199989, Requested 292. Please try again in 2m1.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-4389-GAMMA",
      "context_size": 10,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 750
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 124.79345800238661,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199989, Requested 292. Please try again in 2m1.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-6706-BETA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 750
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact3",
      "score": 0.0,
      "latency_ms": 201.25954199465923,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199989, Requested 291. Please try again in 2m0.96s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-67431",
      "context_size": 10,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 750
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 152.49012599815615,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199988, Requested 294. Please try again in 2m1.824s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "55.59",
      "context_size": 10,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 768
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 153.58945800107904,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199988, Requested 295. Please try again in 2m2.256s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-63090",
      "context_size": 10,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 768
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 188.84341699595097,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199988, Requested 294. Please try again in 2m1.824s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "24.23",
      "context_size": 10,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 768
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 175.02062499988824,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199987, Requested 290. Please try again in 1m59.664s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-4228-BETA",
      "context_size": 10,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 742
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 137.134792006691,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199987, Requested 289. Please try again in 1m59.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-44387",
      "context_size": 10,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 742
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 209.29791599337477,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199987, Requested 288. Please try again in 1m58.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "63.67",
      "context_size": 10,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 742
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 123.04187500558328,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199986, Requested 287. Please try again in 1m57.936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-41270",
      "context_size": 10,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 738
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 134.01366600010078,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199986, Requested 288. Please try again in 1m58.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-2916-ALPHA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 738
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 152.1551250043558,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199985, Requested 288. Please try again in 1m57.936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-3316-GAMMA",
      "context_size": 10,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 738
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 150.72966599836946,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199985, Requested 467. Please try again in 3m15.263999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "15.73",
      "context_size": 25,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 1639
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 136.91104200552218,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199985, Requested 468. Please try again in 3m15.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-45112",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 1639
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact3",
      "score": 0.0,
      "latency_ms": 140.43545800086576,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199984, Requested 467. Please try again in 3m14.832s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "47.69",
      "context_size": 25,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 1639
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 209.99879098962992,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199984, Requested 480. Please try again in 3m20.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-42725",
      "context_size": 25,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 1615
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 171.12762499891687,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199984, Requested 480. Please try again in 3m20.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-52217",
      "context_size": 25,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 1615
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 131.22720799583476,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199983, Requested 480. Please try again in 3m20.016s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-98635",
      "context_size": 25,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 1615
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 232.3235000076238,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199983, Requested 473. Please try again in 3m16.992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-30707",
      "context_size": 25,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 142.28475000709295,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199982, Requested 474. Please try again in 3m16.992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-8479-ALPHA",
      "context_size": 25,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 131.97079200472217,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199982, Requested 474. Please try again in 3m16.992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-4314-GAMMA",
      "context_size": 25,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 117.86812500213273,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199982, Requested 490. Please try again in 3m23.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-3181-GAMMA",
      "context_size": 25,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 1618
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 154.14425000199117,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199981, Requested 488. Please try again in 3m22.607999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "19.08",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 1618
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 130.73104100476485,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199981, Requested 488. Please try again in 3m22.607999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "73.01",
      "context_size": 25,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 1618
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 139.41041700309142,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199981, Requested 796. Please try again in 5m35.664s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1901-BETA",
      "context_size": 50,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 3048
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 130.99179200071376,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199981, Requested 794. Please try again in 5m34.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "95.84",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 3048
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact3",
      "score": 0.0,
      "latency_ms": 142.4610000103712,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199980, Requested 794. Please try again in 5m34.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "23.15",
      "context_size": 50,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 3048
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 144.82183300424367,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199980, Requested 802. Please try again in 5m37.824s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1391-ALPHA",
      "context_size": 50,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 3072
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 150.6652919924818,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199980, Requested 800. Please try again in 5m36.96s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "45.81",
      "context_size": 50,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 3072
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 211.55145799275488,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199979, Requested 800. Please try again in 5m36.528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "2.42",
      "context_size": 50,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 3072
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 161.8792080116691,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199979, Requested 796. Please try again in 5m34.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-25919",
      "context_size": 50,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 3033
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 141.51474999380298,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199978, Requested 796. Please try again in 5m34.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-18083",
      "context_size": 50,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 3033
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 222.92612498858944,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199978, Requested 796. Please try again in 5m34.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-27133",
      "context_size": 50,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 3033
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 147.85295799083542,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199977, Requested 787. Please try again in 5m30.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "46.72",
      "context_size": 50,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 3008
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 133.2594169944059,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199977, Requested 787. Please try again in 5m30.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "19.72",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 3008
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 207.95887500571553,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199977, Requested 788. Please try again in 5m30.479999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-74517",
      "context_size": 50,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 3008
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 341.56491699104663,
      "response": "KEY-1975-ALPHA",
      "expected": "KEY-1975-ALPHA",
      "context_size": 10,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 726
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 270.62875000410713,
      "response": "ID-86888",
      "expected": "ID-86888",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 726
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 270.6678329996066,
      "response": "19.99",
      "expected": "19.99",
      "context_size": 10,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 726
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 273.7597090017516,
      "response": "72.88",
      "expected": "72.88",
      "context_size": 10,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 734
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 241.48958300065715,
      "response": "46.28",
      "expected": "46.28",
      "context_size": 10,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 734
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 261.07491699804086,
      "response": "76.22",
      "expected": "76.22",
      "context_size": 10,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 734
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 279.4359169929521,
      "response": "KEY-2274-ALPHA",
      "expected": "KEY-2274-ALPHA",
      "context_size": 10,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 739
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 274.3035410094308,
      "response": "KEY-6234-ALPHA",
      "expected": "KEY-6234-ALPHA",
      "context_size": 10,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 739
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 264.2154580098577,
      "response": "12.90",
      "expected": "12.90",
      "context_size": 10,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 739
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 276.2113749922719,
      "response": "KEY-9078-BETA",
      "expected": "KEY-9078-BETA",
      "context_size": 10,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 741
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 448.5437080002157,
      "response": "KEY-9946-BETA",
      "expected": "KEY-9946-BETA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 741
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 304.89912499615457,
      "response": "ID-72847",
      "expected": "ID-72847",
      "context_size": 10,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 741
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 272.56608300376683,
      "response": "81.76",
      "expected": "81.76",
      "context_size": 25,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 1627
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 287.45333300321363,
      "response": "KEY-4271-ALPHA",
      "expected": "KEY-4271-ALPHA",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 1627
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 363.2253329997184,
      "response": "ID-37125",
      "expected": "ID-37125",
      "context_size": 25,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 1627
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 289.323292003246,
      "response": "KEY-2293-BETA",
      "expected": "KEY-2293-BETA",
      "context_size": 25,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 1579
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 294.9326250090962,
      "response": "5.64",
      "expected": "5.64",
      "context_size": 25,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 1579
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 287.97700100403745,
      "response": "67.73",
      "expected": "67.73",
      "context_size": 25,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 1579
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 354.9996670044493,
      "response": "KEY-5327-BETA",
      "expected": "KEY-5327-BETA",
      "context_size": 25,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 1623
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 311.58383400179446,
      "response": "63.73",
      "expected": "63.73",
      "context_size": 25,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 1623
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 3313.1690430018352,
      "response": "61.04",
      "expected": "61.04",
      "context_size": 25,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 1623
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 2322.926835011458,
      "response": "ID-18600",
      "expected": "ID-18600",
      "context_size": 25,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 1539
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 4425.3120020002825,
      "response": "KEY-9303-BETA",
      "expected": "KEY-9303-BETA",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 1539
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 3382.6315850019455,
      "response": "ID-78719",
      "expected": "ID-78719",
      "context_size": 25,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 1539
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 6412.626710996847,
      "response": "ID-17441",
      "expected": "ID-17441",
      "context_size": 50,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 3059
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 6563.643378001871,
      "response": "52.84",
      "expected": "52.84",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 3059
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 6488.158669002587,
      "response": "KEY-3292-GAMMA",
      "expected": "KEY-3292-GAMMA",
      "context_size": 50,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 3059
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 6425.470628004405,
      "response": "KEY-7280-ALPHA",
      "expected": "KEY-7280-ALPHA",
      "context_size": 50,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 3083
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 6802.999877996626,
      "response": "ID-79963",
      "expected": "ID-79963",
      "context_size": 50,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 3083
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 6471.90287799458,
      "response": "ID-58903",
      "expected": "ID-58903",
      "context_size": 50,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 3083
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 6499.3135440017795,
      "response": "KEY-6416-ALPHA",
      "expected": "KEY-6416-ALPHA",
      "context_size": 50,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 3120
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 7402.804711993667,
      "response": "ID-11671",
      "expected": "ID-11671",
      "context_size": 50,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 3120
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 6477.027585991891,
      "response": "12.14",
      "expected": "12.14",
      "context_size": 50,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 3120
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 6418.187045012019,
      "response": "79.06",
      "expected": "79.06",
      "context_size": 50,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 3064
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 6465.09796200553,
      "response": "ID-94331",
      "expected": "ID-94331",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 3064
    },
    {
      "benchmark": "ruler",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 6536.1945439944975,
      "response": "ID-76265",
      "expected": "ID-76265",
      "context_size": 50,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 3064
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 2341.5592509991257,
      "response": "58.11",
      "expected": "58.11",
      "context_size": 10,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 708
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 2344.6322520030662,
      "response": "KEY-8324-BETA",
      "expected": "KEY-8324-BETA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 708
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 3373.704251993331,
      "response": "ID-75191",
      "expected": "ID-75191",
      "context_size": 10,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 708
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 2351.1647099949187,
      "response": "ID-69566",
      "expected": "ID-69566",
      "context_size": 10,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 743
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 2362.827250995906,
      "response": "KEY-8751-GAMMA",
      "expected": "KEY-8751-GAMMA",
      "context_size": 10,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 743
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 2327.4404179974226,
      "response": "47.91",
      "expected": "47.91",
      "context_size": 10,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 743
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 3335.8684179984266,
      "response": "KEY-4209-ALPHA",
      "expected": "KEY-4209-ALPHA",
      "context_size": 10,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 731
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 2464.333292999072,
      "response": "ID-61497",
      "expected": "ID-61497",
      "context_size": 10,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 731
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 2356.4227930037305,
      "response": "ID-69905",
      "expected": "ID-69905",
      "context_size": 10,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 731
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 2358.81929199968,
      "response": "100.22",
      "expected": "100.22",
      "context_size": 10,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 724
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 3282.0096260111313,
      "response": "75.22",
      "expected": "75.22",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 724
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 2426.0378350008978,
      "response": "17.13",
      "expected": "17.13",
      "context_size": 10,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 724
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 1379.753458997584,
      "response": "ID-13312",
      "expected": "ID-13312",
      "context_size": 25,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 1548
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 4469.410669000354,
      "response": "KEY-3381-ALPHA",
      "expected": "KEY-3381-ALPHA",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 1548
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 3383.7375849980162,
      "response": "8.25",
      "expected": "8.25",
      "context_size": 25,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 1548
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 4318.073002010351,
      "response": "ID-66165",
      "expected": "ID-66165",
      "context_size": 25,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 1592
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 4427.8211269993335,
      "response": "KEY-5329-ALPHA",
      "expected": "KEY-5329-ALPHA",
      "context_size": 25,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 1592
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 3334.4645850011148,
      "response": "ID-86544",
      "expected": "ID-86544",
      "context_size": 25,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 1592
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 4335.511169003439,
      "response": "KEY-7248-ALPHA",
      "expected": "KEY-7248-ALPHA",
      "context_size": 25,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 1580
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 4346.430917998077,
      "response": "KEY-5203-GAMMA",
      "expected": "KEY-5203-GAMMA",
      "context_size": 25,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 1580
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 4402.908461008337,
      "response": "37.03",
      "expected": "37.03",
      "context_size": 25,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 1580
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 4368.309751997003,
      "response": "KEY-2938-GAMMA",
      "expected": "KEY-2938-GAMMA",
      "context_size": 25,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 1605
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 3378.786625995417,
      "response": "ID-94072",
      "expected": "ID-94072",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 1605
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 4399.013044007006,
      "response": "80.08",
      "expected": "80.08",
      "context_size": 25,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 1605
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 6390.199251996819,
      "response": "94.42",
      "expected": "94.42",
      "context_size": 50,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 3086
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 6444.168002999504,
      "response": "KEY-8583-BETA",
      "expected": "KEY-8583-BETA",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 3086
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 6527.065960995969,
      "response": "KEY-6004-BETA",
      "expected": "KEY-6004-BETA",
      "context_size": 50,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 3086
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 478.0675830115797,
      "response": "ID-67658",
      "expected": "ID-67658",
      "context_size": 50,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 3080
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 6386.566002998734,
      "response": "ID-40145",
      "expected": "ID-40145",
      "context_size": 50,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 3080
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 6389.918877990567,
      "response": "ID-77441",
      "expected": "ID-77441",
      "context_size": 50,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 3080
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 6458.183711001766,
      "response": "KEY-6742-GAMMA",
      "expected": "KEY-6742-GAMMA",
      "context_size": 50,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 3142
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 6453.946793990326,
      "response": "98.89",
      "expected": "98.89",
      "context_size": 50,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 3142
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 6395.502003011643,
      "response": "13.54",
      "expected": "13.54",
      "context_size": 50,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 3142
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 6553.6528779921355,
      "response": "ID-88579",
      "expected": "ID-88579",
      "context_size": 50,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 3039
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 6449.400836994755,
      "response": "67.89",
      "expected": "67.89",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 3039
    },
    {
      "benchmark": "ruler",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 6336.568294995232,
      "response": "ID-90634",
      "expected": "ID-90634",
      "context_size": 50,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 3039
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 476.40829099691473,
      "response": "ID-82036",
      "expected": "ID-82036",
      "context_size": 10,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 751
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 351.4005829929374,
      "response": "KEY-6703-BETA",
      "expected": "KEY-6703-BETA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 751
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 1332.059375999961,
      "response": "KEY-4707-GAMMA",
      "expected": "KEY-4707-GAMMA",
      "context_size": 10,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 751
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 3332.453543000156,
      "response": "KEY-7178-GAMMA",
      "expected": "KEY-7178-GAMMA",
      "context_size": 10,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 758
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 2321.7030429950682,
      "response": "KEY-4985-BETA",
      "expected": "KEY-4985-BETA",
      "context_size": 10,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 758
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 1326.2430840113666,
      "response": "KEY-8548-GAMMA",
      "expected": "KEY-8548-GAMMA",
      "context_size": 10,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 758
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 2343.621000996791,
      "response": "KEY-6603-ALPHA",
      "expected": "KEY-6603-ALPHA",
      "context_size": 10,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 737
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 3406.0567100095795,
      "response": "23.60",
      "expected": "23.60",
      "context_size": 10,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 737
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 2361.043791999691,
      "response": "KEY-6792-ALPHA",
      "expected": "KEY-6792-ALPHA",
      "context_size": 10,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 737
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 2351.8257929972606,
      "response": "64.78",
      "expected": "64.78",
      "context_size": 10,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 707
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 3315.8064180024667,
      "response": "ID-80972",
      "expected": "ID-80972",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 707
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 2458.156876004068,
      "response": "ID-73214",
      "expected": "ID-73214",
      "context_size": 10,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 707
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 4354.935793991899,
      "response": "KEY-5581-BETA",
      "expected": "KEY-5581-BETA",
      "context_size": 25,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 1586
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 3426.2405850022333,
      "response": "ID-84895",
      "expected": "ID-84895",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 1586
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 4325.025418002042,
      "response": "ID-85483",
      "expected": "ID-85483",
      "context_size": 25,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 1586
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 3381.620460000704,
      "response": "78.25",
      "expected": "78.25",
      "context_size": 25,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 1624
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 4405.298961006338,
      "response": "74.83",
      "expected": "74.83",
      "context_size": 25,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 1624
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 3326.3209180004196,
      "response": "69.22",
      "expected": "69.22",
      "context_size": 25,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 1624
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 4384.626668994315,
      "response": "ID-62041",
      "expected": "ID-62041",
      "context_size": 25,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 4476.6442099935375,
      "response": "ID-22524",
      "expected": "ID-22524",
      "context_size": 25,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 3308.7265020003542,
      "response": "ID-72021",
      "expected": "ID-72021",
      "context_size": 25,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 1595
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 3316.9392100098776,
      "response": "ID-49789",
      "expected": "ID-49789",
      "context_size": 25,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 1592
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 4321.3310430001,
      "response": "ID-10012",
      "expected": "ID-10012",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 1592
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 4315.759585995693,
      "response": "98.17",
      "expected": "98.17",
      "context_size": 25,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 1592
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact1",
      "score": 1.0,
      "latency_ms": 6457.862127994304,
      "response": "ID-25985",
      "expected": "ID-25985",
      "context_size": 50,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 3018
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact2",
      "score": 1.0,
      "latency_ms": 5513.914295006543,
      "response": "32.49",
      "expected": "32.49",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 3018
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact3",
      "score": 1.0,
      "latency_ms": 6483.4337110078195,
      "response": "KEY-5049-GAMMA",
      "expected": "KEY-5049-GAMMA",
      "context_size": 50,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 3018
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact1",
      "score": 1.0,
      "latency_ms": 6407.453670006362,
      "response": "ID-93627",
      "expected": "ID-93627",
      "context_size": 50,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 3083
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact2",
      "score": 1.0,
      "latency_ms": 6426.827960996889,
      "response": "49.93",
      "expected": "49.93",
      "context_size": 50,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 3083
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact3",
      "score": 1.0,
      "latency_ms": 295.46866699820384,
      "response": "ID-12453",
      "expected": "ID-12453",
      "context_size": 50,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 3083
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact1",
      "score": 1.0,
      "latency_ms": 6397.992960992269,
      "response": "KEY-6163-GAMMA",
      "expected": "KEY-6163-GAMMA",
      "context_size": 50,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 3055
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact2",
      "score": 1.0,
      "latency_ms": 6456.931169013842,
      "response": "KEY-7090-BETA",
      "expected": "KEY-7090-BETA",
      "context_size": 50,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 3055
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact3",
      "score": 1.0,
      "latency_ms": 6419.352294993587,
      "response": "56.92",
      "expected": "56.92",
      "context_size": 50,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 3055
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact1",
      "score": 1.0,
      "latency_ms": 6462.80246101378,
      "response": "96.06",
      "expected": "96.06",
      "context_size": 50,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 3023
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact2",
      "score": 1.0,
      "latency_ms": 6422.908252992784,
      "response": "52.33",
      "expected": "52.33",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 3023
    },
    {
      "benchmark": "ruler",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact3",
      "score": 1.0,
      "latency_ms": 6415.849961995264,
      "response": "ID-62235",
      "expected": "ID-62235",
      "context_size": 50,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 3023
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 5669.993128001806,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 213. Please try again in 1m32.015999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "53.54",
      "context_size": 10,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 735
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 397.76125000207685,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 247. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-6706-ALPHA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 735
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact3",
      "score": 0.0,
      "latency_ms": 78.5325000033481,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 247. Please try again in 1m45.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-6644-GAMMA",
      "context_size": 10,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 735
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 85.88062500348315,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 245. Please try again in 1m44.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "19.36",
      "context_size": 10,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 744
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 86.29104199644644,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199997, Requested 246. Please try again in 1m44.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-54993",
      "context_size": 10,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 744
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 321.93058299890254,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199996, Requested 245. Please try again in 1m44.112s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "15.39",
      "context_size": 10,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 744
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 100.13604200503323,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199996, Requested 247. Please try again in 1m44.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-4288-GAMMA",
      "context_size": 10,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 758
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 85.95737499126699,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199995, Requested 245. Please try again in 1m43.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "35.06",
      "context_size": 10,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 758
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 188.12620799872093,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199995, Requested 247. Please try again in 1m44.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1136-ALPHA",
      "context_size": 10,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 758
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 349.7663750022184,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199994, Requested 248. Please try again in 1m44.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-75621",
      "context_size": 10,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 715
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 76.36470800207462,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199994, Requested 247. Please try again in 1m44.112s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1352-ALPHA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 715
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 175.865083001554,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199994, Requested 246. Please try again in 1m43.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-79391",
      "context_size": 10,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 715
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 76.676624987158,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199993, Requested 247. Please try again in 1m43.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "91.67",
      "context_size": 25,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 1612
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 79.73483399837278,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199993, Requested 246. Please try again in 1m43.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-66369",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 1612
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact3",
      "score": 0.0,
      "latency_ms": 94.80649999750312,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199993, Requested 246. Please try again in 1m43.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-96013",
      "context_size": 25,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 1612
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 92.44224999565631,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199993, Requested 246. Please try again in 1m43.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-14224",
      "context_size": 25,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 1615
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 139.77370799693745,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199992, Requested 247. Please try again in 1m43.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1245-BETA",
      "context_size": 25,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 1615
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 106.87929099367466,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199992, Requested 247. Please try again in 1m43.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-4646-GAMMA",
      "context_size": 25,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 1615
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 75.99812500120606,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199992, Requested 246. Please try again in 1m42.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-65372",
      "context_size": 25,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 1574
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 65.39970901212655,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199992, Requested 247. Please try again in 1m43.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1893-GAMMA",
      "context_size": 25,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 1574
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 81.22000099683646,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199992, Requested 245. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "19.59",
      "context_size": 25,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 1574
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 157.5832919916138,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199992, Requested 246. Please try again in 1m42.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-36588",
      "context_size": 25,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 1642
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 74.44920799753163,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199991, Requested 246. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-91600",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 1642
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 85.35291699809022,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199991, Requested 247. Please try again in 1m42.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1200-BETA",
      "context_size": 25,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 1642
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 76.73449999128934,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199991, Requested 245. Please try again in 1m41.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "16.94",
      "context_size": 50,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 3091
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 86.46095900621731,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199991, Requested 246. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-90649",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 3091
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact3",
      "score": 0.0,
      "latency_ms": 85.7688749965746,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199990, Requested 247. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-7783-ALPHA",
      "context_size": 50,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 3091
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 157.68575000402052,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199990, Requested 247. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-8921-GAMMA",
      "context_size": 50,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 3059
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 95.76358299818821,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199990, Requested 245. Please try again in 1m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "40.99",
      "context_size": 50,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 3059
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 86.75345800293144,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199990, Requested 247. Please try again in 1m42.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-3347-ALPHA",
      "context_size": 50,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 3059
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 76.96958399901632,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199989, Requested 245. Please try again in 1m41.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "43.41",
      "context_size": 50,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 3057
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 99.54991699487437,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199989, Requested 247. Please try again in 1m41.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-8987-ALPHA",
      "context_size": 50,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 3057
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 164.0447500103619,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199989, Requested 246. Please try again in 1m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-72303",
      "context_size": 50,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 3057
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 73.4593329980271,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199989, Requested 247. Please try again in 1m41.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1510-ALPHA",
      "context_size": 50,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 3064
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 91.81487599562388,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199988, Requested 247. Please try again in 1m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-7459-GAMMA",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 3064
    },
    {
      "benchmark": "ruler",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 81.04829098738264,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199988, Requested 247. Please try again in 1m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-7271-BETA",
      "context_size": 50,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 3064
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 304.01641700882465,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199988, Requested 282. Please try again in 1m56.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "3.18",
      "context_size": 10,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 737
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 144.5551670040004,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199987, Requested 282. Please try again in 1m56.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "63.84",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 737
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.10_0.50_0.90_fact3",
      "score": 0.0,
      "latency_ms": 137.85008400736842,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199987, Requested 284. Please try again in 1m57.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-3224-ALPHA",
      "context_size": 10,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 737
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 202.8276250057388,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199986, Requested 283. Please try again in 1m56.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-4878-GAMMA",
      "context_size": 10,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 741
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 232.51762498694006,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199986, Requested 281. Please try again in 1m55.344s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "35.52",
      "context_size": 10,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 741
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 258.6891250102781,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199985, Requested 281. Please try again in 1m54.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "74.46",
      "context_size": 10,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 741
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 194.23466599255335,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199985, Requested 294. Please try again in 2m0.527999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "70.74",
      "context_size": 10,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 752
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 133.93287500366569,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199985, Requested 296. Please try again in 2m1.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1864-BETA",
      "context_size": 10,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 752
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 232.9914580041077,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199984, Requested 294. Please try again in 2m0.095999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "100.01",
      "context_size": 10,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 752
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 192.05241699819453,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199984, Requested 285. Please try again in 1m56.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-96025",
      "context_size": 10,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 729
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 142.7051669888897,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199983, Requested 286. Please try again in 1m56.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-1447-BETA",
      "context_size": 10,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 729
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size10_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 195.40829199831933,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199983, Requested 286. Please try again in 1m56.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-2351-ALPHA",
      "context_size": 10,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 729
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 136.10383399645798,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199982, Requested 486. Please try again in 3m22.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-8802-BETA",
      "context_size": 25,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 1683
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 127.90554099774454,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199982, Requested 486. Please try again in 3m22.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-9724-ALPHA",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 1683
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.10_0.50_0.90_fact3",
      "score": 0.0,
      "latency_ms": 451.09354201122187,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199982, Requested 486. Please try again in 3m22.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-7390-BETA",
      "context_size": 25,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 1683
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 198.49908399919514,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199981, Requested 470. Please try again in 3m14.832s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-91185",
      "context_size": 25,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 1569
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 164.126750009018,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199980, Requested 470. Please try again in 3m14.399999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-17455",
      "context_size": 25,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 1569
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 145.12400000239722,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199980, Requested 469. Please try again in 3m13.968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "85.27",
      "context_size": 25,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 1569
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 135.91304200235754,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199980, Requested 476. Please try again in 3m16.992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "83.13",
      "context_size": 25,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 1642
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 304.0597500075819,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199979, Requested 478. Please try again in 3m17.424s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-5243-ALPHA",
      "context_size": 25,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 1642
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 579.0056670084596,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199979, Requested 477. Please try again in 3m16.992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-19557",
      "context_size": 25,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 1642
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 157.89908298756927,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199977, Requested 470. Please try again in 3m13.104s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "6.49",
      "context_size": 25,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 1585
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 211.25925000524148,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199977, Requested 470. Please try again in 3m13.104s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "25.38",
      "context_size": 25,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 1585
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size25_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 310.7270000036806,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199976, Requested 470. Please try again in 3m12.672s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "50.13",
      "context_size": 25,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 1585
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact1",
      "score": 0.0,
      "latency_ms": 239.27966700284742,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199975, Requested 814. Please try again in 5m40.847999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-2322-ALPHA",
      "context_size": 50,
      "fact_position": 0.1,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 1,
      "context_chars": 3132
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact2",
      "score": 0.0,
      "latency_ms": 173.3118749980349,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199975, Requested 813. Please try again in 5m40.416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-33516",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 2,
      "context_chars": 3132
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.10_0.50_0.90_fact3",
      "score": 0.0,
      "latency_ms": 139.26795800216496,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199975, Requested 813. Please try again in 5m40.416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-95426",
      "context_size": 50,
      "fact_position": 0.9,
      "position_set": [
        0.1,
        0.5,
        0.9
      ],
      "fact_id": 3,
      "context_chars": 3132
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact1",
      "score": 0.0,
      "latency_ms": 185.89733399858233,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199974, Requested 817. Please try again in 5m41.712s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "59.22",
      "context_size": 50,
      "fact_position": 0.2,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 1,
      "context_chars": 3064
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact2",
      "score": 0.0,
      "latency_ms": 178.38791699614376,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199974, Requested 819. Please try again in 5m42.575999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-7119-ALPHA",
      "context_size": 50,
      "fact_position": 0.4,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 2,
      "context_chars": 3064
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.20_0.40_0.60_fact3",
      "score": 0.0,
      "latency_ms": 164.9829590023728,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199973, Requested 819. Please try again in 5m42.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-4181-GAMMA",
      "context_size": 50,
      "fact_position": 0.6,
      "position_set": [
        0.2,
        0.4,
        0.6
      ],
      "fact_id": 3,
      "context_chars": 3064
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact1",
      "score": 0.0,
      "latency_ms": 182.59079100971576,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199973, Requested 790. Please try again in 5m29.616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-48874",
      "context_size": 50,
      "fact_position": 0.05,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 1,
      "context_chars": 3042
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact2",
      "score": 0.0,
      "latency_ms": 157.8819169953931,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199973, Requested 791. Please try again in 5m30.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "KEY-5420-GAMMA",
      "context_size": 50,
      "fact_position": 0.15,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 2,
      "context_chars": 3042
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.05_0.15_0.95_fact3",
      "score": 0.0,
      "latency_ms": 142.9591670021182,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199972, Requested 789. Please try again in 5m28.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "70.73",
      "context_size": 50,
      "fact_position": 0.95,
      "position_set": [
        0.05,
        0.15,
        0.95
      ],
      "fact_id": 3,
      "context_chars": 3042
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact1",
      "score": 0.0,
      "latency_ms": 233.75641700113192,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199972, Requested 802. Please try again in 5m34.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-50172",
      "context_size": 50,
      "fact_position": 0.45,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 1,
      "context_chars": 3043
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact2",
      "score": 0.0,
      "latency_ms": 234.39808300463483,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199971, Requested 802. Please try again in 5m33.936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-44079",
      "context_size": 50,
      "fact_position": 0.5,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 2,
      "context_chars": 3043
    },
    {
      "benchmark": "ruler",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "ruler_size50_pos0.45_0.50_0.55_fact3",
      "score": 0.0,
      "latency_ms": 248.9215840032557,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199971, Requested 802. Please try again in 5m33.936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ID-73470",
      "context_size": 50,
      "fact_position": 0.55,
      "position_set": [
        0.45,
        0.5,
        0.55
      ],
      "fact_id": 3,
      "context_chars": 3043
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_1",
      "score": 0.0,
      "latency_ms": 684.3184580066008,
      "response": "O crescimento percentual nas vendas do terceiro trimestre foi de **23 %**.",
      "expected": "23%",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_2",
      "score": 1.0,
      "latency_ms": 362.4142920016311,
      "response": "5555",
      "expected": "5555",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_3",
      "score": 0.0,
      "latency_ms": 124.72387500747573,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199982, Requested 657. Please try again in 4m36.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "Sudeste",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_4",
      "score": 0.0,
      "latency_ms": 49.56233300617896,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199982, Requested 656. Please try again in 4m35.616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ARM Cortex-M4",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_5",
      "score": 0.0,
      "latency_ms": 48.11787500511855,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199982, Requested 655. Please try again in 4m35.183999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "15 de abril às 10h",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-120b",
      "test_case": "longbench_summarization_1",
      "score": 0.0,
      "latency_ms": 56.66916699556168,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199982, Requested 317. Please try again in 2m9.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "inteligência artificial setores desafios ética",
      "task_type": "summarization",
      "expected_topics": [
        "inteligência artificial",
        "setores",
        "desafios",
        "ética"
      ],
      "context_chars": 1015
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_1",
      "score": 0.0,
      "latency_ms": 97.49837500567082,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199982, Requested 621. Please try again in 4m20.495999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "24 meses",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_2",
      "score": 0.0,
      "latency_ms": 149.57916700222995,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199981, Requested 623. Please try again in 4m20.928s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "Sudeste",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_3",
      "score": 0.0,
      "latency_ms": 46.66500000166707,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199981, Requested 621. Please try again in 4m20.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "5555",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_4",
      "score": 0.0,
      "latency_ms": 40.765166995697655,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199981, Requested 626. Please try again in 4m22.224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "nível 3",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_5",
      "score": 0.0,
      "latency_ms": 46.10145899641793,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199981, Requested 624. Please try again in 4m21.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "23%",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-120b",
      "test_case": "longbench_summarization_1",
      "score": 0.0,
      "latency_ms": 44.01820900966413,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199981, Requested 310. Please try again in 2m5.711999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "inteligência artificial setores desafios ética",
      "task_type": "summarization",
      "expected_topics": [
        "inteligência artificial",
        "setores",
        "desafios",
        "ética"
      ],
      "context_chars": 1015
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_1",
      "score": 0.0,
      "latency_ms": 108.23820799123496,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199981, Requested 626. Please try again in 4m22.224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "nível 3",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_2",
      "score": 0.0,
      "latency_ms": 532.9325000056997,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199980, Requested 621. Please try again in 4m19.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "24 meses",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_3",
      "score": 0.0,
      "latency_ms": 66.95274999947287,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199979, Requested 621. Please try again in 4m19.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "5555",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_4",
      "score": 0.0,
      "latency_ms": 40.26533299474977,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199979, Requested 622. Please try again in 4m19.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ARM Cortex-M4",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_5",
      "score": 0.0,
      "latency_ms": 161.027334004757,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199979, Requested 624. Please try again in 4m20.495999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "23%",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-120b",
      "test_case": "longbench_summarization_1",
      "score": 0.0,
      "latency_ms": 43.051208995166235,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199979, Requested 310. Please try again in 2m4.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "inteligência artificial setores desafios ética",
      "task_type": "summarization",
      "expected_topics": [
        "inteligência artificial",
        "setores",
        "desafios",
        "ética"
      ],
      "context_chars": 1015
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_1",
      "score": 0.0,
      "latency_ms": 1067.2885419917293,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199976, Requested 243. Please try again in 1m34.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "24 meses",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_2",
      "score": 0.0,
      "latency_ms": 84.57329199882224,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199976, Requested 244. Please try again in 1m35.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ARM Cortex-M4",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_3",
      "score": 0.0,
      "latency_ms": 93.33104199322406,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199976, Requested 245. Please try again in 1m35.472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "Sudeste",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_4",
      "score": 0.0,
      "latency_ms": 93.08391698868945,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199976, Requested 248. Please try again in 1m36.767999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "nível 3",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_5",
      "score": 0.0,
      "latency_ms": 294.12645898992196,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199975, Requested 243. Please try again in 1m34.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "5555",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-120b",
      "test_case": "longbench_summarization_1",
      "score": 0.0,
      "latency_ms": 83.67308400920592,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199975, Requested 253. Please try again in 1m38.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "inteligência artificial setores desafios ética",
      "task_type": "summarization",
      "expected_topics": [
        "inteligência artificial",
        "setores",
        "desafios",
        "ética"
      ],
      "context_chars": 1015
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_1",
      "score": 0.0,
      "latency_ms": 412.79458299686667,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199974, Requested 626. Please try again in 4m19.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "R$ 15 milhões",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_2",
      "score": 0.0,
      "latency_ms": 177.43495799368247,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199973, Requested 624. Please try again in 4m17.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ARM Cortex-M4",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_3",
      "score": 0.0,
      "latency_ms": 451.43025000288617,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199973, Requested 623. Please try again in 4m17.471999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "24 meses",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_4",
      "score": 0.0,
      "latency_ms": 187.71058399579488,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199972, Requested 624. Please try again in 4m17.471999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "64",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "longbench_multidoc_qa_5",
      "score": 0.0,
      "latency_ms": 204.48220800608397,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199971, Requested 625. Please try again in 4m17.471999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "Sudeste",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-120b",
      "test_case": "longbench_summarization_1",
      "score": 0.0,
      "latency_ms": 158.1660420051776,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199971, Requested 310. Please try again in 2m1.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "inteligência artificial setores desafios ética",
      "task_type": "summarization",
      "expected_topics": [
        "inteligência artificial",
        "setores",
        "desafios",
        "ética"
      ],
      "context_chars": 1015
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_1",
      "score": 0.0,
      "latency_ms": 130.33749999885913,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199957, Requested 657. Please try again in 4m25.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "Sudeste",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_2",
      "score": 0.0,
      "latency_ms": 35.968042007880285,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199956, Requested 655. Please try again in 4m23.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "24 meses",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_3",
      "score": 0.0,
      "latency_ms": 108.75929199391976,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199956, Requested 660. Please try again in 4m26.111999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "nível 3",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_4",
      "score": 0.0,
      "latency_ms": 579.2027920106193,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199956, Requested 658. Please try again in 4m25.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "23%",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_5",
      "score": 0.0,
      "latency_ms": 79.26012499956414,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199955, Requested 658. Please try again in 4m24.815999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "R$ 15 milhões",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "raw_gpt-oss-20b",
      "test_case": "longbench_summarization_1",
      "score": 0.0,
      "latency_ms": 35.81537499849219,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199955, Requested 317. Please try again in 1m57.504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "inteligência artificial setores desafios ética",
      "task_type": "summarization",
      "expected_topics": [
        "inteligência artificial",
        "setores",
        "desafios",
        "ética"
      ],
      "context_chars": 1015
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_1",
      "score": 0.0,
      "latency_ms": 115.40525101008825,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199954, Requested 624. Please try again in 4m9.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "23%",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_2",
      "score": 0.0,
      "latency_ms": 41.76149998966139,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199954, Requested 622. Please try again in 4m8.832s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "64",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_3",
      "score": 0.0,
      "latency_ms": 39.35208299662918,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199954, Requested 621. Please try again in 4m8.4s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "5555",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_4",
      "score": 0.0,
      "latency_ms": 44.209500003489666,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199954, Requested 621. Please try again in 4m8.4s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "24 meses",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_5",
      "score": 0.0,
      "latency_ms": 115.68720800278243,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199954, Requested 626. Please try again in 4m10.559999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "nível 3",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "sliding_window_gpt-oss-20b",
      "test_case": "longbench_summarization_1",
      "score": 0.0,
      "latency_ms": 60.217332997126505,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199954, Requested 310. Please try again in 1m54.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "inteligência artificial setores desafios ética",
      "task_type": "summarization",
      "expected_topics": [
        "inteligência artificial",
        "setores",
        "desafios",
        "ética"
      ],
      "context_chars": 1015
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_1",
      "score": 0.0,
      "latency_ms": 108.40337499394082,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199953, Requested 621. Please try again in 4m7.968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "15 de abril às 10h",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_2",
      "score": 0.0,
      "latency_ms": 54.84720900130924,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199953, Requested 626. Please try again in 4m10.128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "nível 3",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_3",
      "score": 0.0,
      "latency_ms": 41.3599999883445,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199953, Requested 621. Please try again in 4m7.968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "24 meses",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_4",
      "score": 0.0,
      "latency_ms": 38.053083000704646,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199953, Requested 624. Please try again in 4m9.264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "23%",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_5",
      "score": 0.0,
      "latency_ms": 1398.3212090097368,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199953, Requested 622. Please try again in 4m8.4s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ARM Cortex-M4",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "parallel_window_gpt-oss-20b",
      "test_case": "longbench_summarization_1",
      "score": 0.0,
      "latency_ms": 63.99141700239852,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199950, Requested 310. Please try again in 1m52.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "inteligência artificial setores desafios ética",
      "task_type": "summarization",
      "expected_topics": [
        "inteligência artificial",
        "setores",
        "desafios",
        "ética"
      ],
      "context_chars": 1015
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_1",
      "score": 0.0,
      "latency_ms": 188.366041998961,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199949, Requested 243. Please try again in 1m22.944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "5555",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_2",
      "score": 0.0,
      "latency_ms": 177.47708399838302,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199949, Requested 245. Please try again in 1m23.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "Sudeste",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_3",
      "score": 0.0,
      "latency_ms": 115.5283749976661,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199949, Requested 244. Please try again in 1m23.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "ARM Cortex-M4",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_4",
      "score": 0.0,
      "latency_ms": 86.80991599976551,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199948, Requested 244. Please try again in 1m22.944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "64",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_5",
      "score": 0.0,
      "latency_ms": 76.23162498930469,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199948, Requested 246. Please try again in 1m23.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "23%",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "semantic_compression_gpt-oss-20b",
      "test_case": "longbench_summarization_1",
      "score": 0.0,
      "latency_ms": 1068.9043759921333,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199946, Requested 253. Please try again in 1m25.968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "inteligência artificial setores desafios ética",
      "task_type": "summarization",
      "expected_topics": [
        "inteligência artificial",
        "setores",
        "desafios",
        "ética"
      ],
      "context_chars": 1015
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_1",
      "score": 0.0,
      "latency_ms": 262.88562499394175,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199945, Requested 624. Please try again in 4m5.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "64",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_2",
      "score": 0.0,
      "latency_ms": 1038.0049590021372,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199945, Requested 623. Please try again in 4m5.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "15 de abril às 10h",
      "task_type": "multi_doc_qa",
      "source_doc": "Manual de Procedimentos de Segurança",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_3",
      "score": 0.0,
      "latency_ms": 328.2573750038864,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199942, Requested 625. Please try again in 4m4.944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "Sudeste",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_4",
      "score": 0.0,
      "latency_ms": 169.8631250037579,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199942, Requested 626. Please try again in 4m5.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "R$ 15 milhões",
      "task_type": "multi_doc_qa",
      "source_doc": "Relatório Trimestral de Vendas",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "longbench_multidoc_qa_5",
      "score": 0.0,
      "latency_ms": 146.74574999662582,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199941, Requested 623. Please try again in 4m3.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "24 meses",
      "task_type": "multi_doc_qa",
      "source_doc": "Especificação Técnica do Produto XYZ-500",
      "context_chars": 2217,
      "num_documents": 3
    },
    {
      "benchmark": "longbench",
      "strategy": "rig_gpt-oss-20b",
      "test_case": "longbench_summarization_1",
      "score": 0.0,
      "latency_ms": 470.6677909998689,
      "response": "[Erro: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-20b` in organization `org_01j6ncxh6denfvxf24n475brwe` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199941, Requested 310. Please try again in 1m48.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}]",
      "expected": "inteligência artificial setores desafios ética",
      "task_type": "summarization",
      "expected_topics": [
        "inteligência artificial",
        "setores",
        "desafios",
        "ética"
      ],
      "context_chars": 1015
    }
  ],
  "summary": {
    "total_tests": 570,
    "strategies": {
      "raw_gpt-oss-120b": {
        "avg_score": 0.6842105263157895,
        "min_score": 0.0,
        "max_score": 1.0,
        "avg_latency_ms": 2353.6394571945716,
        "num_tests": 57
      },
      "sliding_window_gpt-oss-120b": {
        "avg_score": 0.7368421052631579,
        "min_score": 0.0,
        "max_score": 1.0,
        "avg_latency_ms": 4495.3696424564805,
        "num_tests": 57
      },
      "parallel_window_gpt-oss-120b": {
        "avg_score": 0.7192982456140351,
        "min_score": 0.0,
        "max_score": 1.0,
        "avg_latency_ms": 4470.219649719901,
        "num_tests": 57
      },
      "semantic_compression_gpt-oss-120b": {
        "avg_score": 0.34210526315789475,
        "min_score": 0.0,
        "max_score": 1.0,
        "avg_latency_ms": 5309.346169843737,
        "num_tests": 57
      },
      "rig_gpt-oss-120b": {
        "avg_score": 0.2596491228070176,
        "min_score": 0.0,
        "max_score": 1.0,
        "avg_latency_ms": 2030.4748378252393,
        "num_tests": 57
      },
      "raw_gpt-oss-20b": {
        "avg_score": 0.8947368421052632,
        "min_score": 0.0,
        "max_score": 1.0,
        "avg_latency_ms": 2567.934106386179,
        "num_tests": 57
      },
      "sliding_window_gpt-oss-20b": {
        "avg_score": 0.8947368421052632,
        "min_score": 0.0,
        "max_score": 1.0,
        "avg_latency_ms": 4610.381719947327,
        "num_tests": 57
      },
      "parallel_window_gpt-oss-20b": {
        "avg_score": 0.8947368421052632,
        "min_score": 0.0,
        "max_score": 1.0,
        "avg_latency_ms": 4418.455700912378,
        "num_tests": 57
      },
      "semantic_compression_gpt-oss-20b": {
        "avg_score": 0.21052631578947367,
        "min_score": 0.0,
        "max_score": 1.0,
        "avg_latency_ms": 4023.613250437305,
        "num_tests": 57
      },
      "rig_gpt-oss-20b": {
        "avg_score": 0.2631578947368421,
        "min_score": 0.0,
        "max_score": 1.0,
        "avg_latency_ms": 2030.7150637728914,
        "num_tests": 57
      }
    },
    "benchmarks": {
      "needle_in_haystack": {
        "avg_score": 0.9653333333333334,
        "num_tests": 150
      },
      "ruler": {
        "avg_score": 0.5291666666666667,
        "num_tests": 360
      },
      "longbench": {
        "avg_score": 0.016666666666666666,
        "num_tests": 60
      }
    },
    "strategy_x_benchmark_matrix": {
      "raw_gpt-oss-120b": {
        "needle_in_haystack": 1.0,
        "ruler": 0.6388888888888888,
        "longbench": 0.16666666666666666
      },
      "sliding_window_gpt-oss-120b": {
        "needle_in_haystack": 0.8666666666666667,
        "ruler": 0.8055555555555556,
        "longbench": 0.0
      },
      "parallel_window_gpt-oss-120b": {
        "needle_in_haystack": 1.0,
        "ruler": 0.7222222222222222,
        "longbench": 0.0
      },
      "semantic_compression_gpt-oss-120b": {
        "needle_in_haystack": 1.0,
        "ruler": 0.125,
        "longbench": 0.0
      },
      "rig_gpt-oss-120b": {
        "needle_in_haystack": 0.9866666666666667,
        "ruler": 0.0,
        "longbench": 0.0
      },
      "raw_gpt-oss-20b": {
        "needle_in_haystack": 1.0,
        "ruler": 1.0,
        "longbench": 0.0
      },
      "sliding_window_gpt-oss-20b": {
        "needle_in_haystack": 1.0,
        "ruler": 1.0,
        "longbench": 0.0
      },
      "parallel_window_gpt-oss-20b": {
        "needle_in_haystack": 1.0,
        "ruler": 1.0,
        "longbench": 0.0
      },
      "semantic_compression_gpt-oss-20b": {
        "needle_in_haystack": 0.8,
        "ruler": 0.0,
        "longbench": 0.0
      },
      "rig_gpt-oss-20b": {
        "needle_in_haystack": 1.0,
        "ruler": 0.0,
        "longbench": 0.0
      }
    }
  }
}