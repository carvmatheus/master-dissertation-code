# Reposit√≥rio de C√≥digo da Disserta√ß√£o de Mestrado

Este reposit√≥rio centraliza os c√≥digos desenvolvidos para a disserta√ß√£o de mestrado. O projeto est√° organizado em m√≥dulos que refletem as etapas da pesquisa, desde a compara√ß√£o de t√©cnicas de extens√£o de contexto at√© a proposta do framework socr√°tico.

## Estrutura do Projeto

### üìÇ `01-context-extension-comparison/`
Este m√≥dulo foca na an√°lise comparativa de **Estrat√©gias N√£o-Invasivas para Extens√£o de Contexto**. Ele implementa um chat modular que permite testar diferentes t√©cnicas de pr√©-processamento de prompt antes de enviar os dados ao LLM.

**Estrat√©gias Implementadas:**
- **Compress√£o Sem√¢ntica (Semantic Compression):** Utiliza um LLM (via Groq API) para reescrever o contexto de forma concisa, preservando entidades e rela√ß√µes (Baseado em *Gilbert et al., 2023*).
- **Compress√£o por Perplexidade (Perplexity-based):** Utiliza um modelo proxy pequeno (ex: GPT-2) para remover tokens de baixa entropia/informa√ß√£o (Baseado em *LLMLingua, Jiang et al., 2023*).
- **Janela Deslizante (Sliding Window):** Segmenta√ß√£o do texto em blocos com sobreposi√ß√£o para processamento sequencial ou paralelo.
- **RIG - Dartboard Ranking:** Combina tr√™s sinais para ranquear chunks: similaridade sem√¢ntica (embeddings), similaridade lexical (TF-IDF) e import√¢ncia do documento. Baseado na estrutura Dartboard.

**Arquivos:**
- `chat.py`: Orquestrador central. Carrega o texto da disserta√ß√£o e inicia o loop de chat.
- `prompt_compression.py`: M√≥dulo contendo as classes de compress√£o.
- `context_strategies.py`: M√≥dulo contendo l√≥gicas de janelamento e segmenta√ß√£o.
- `rig/`: Subm√≥dulo com o processador Dartboard para RAG h√≠brido.

---

### üìÇ `02-socratic-framework/`
*(Em desenvolvimento)*
Este m√≥dulo conter√° a implementa√ß√£o do **Framework Socr√°tico com Contra-exemplos**. O objetivo √© criar um agente que utiliza RAG e Mem√≥ria Externa para gerar refuta√ß√µes (Elenchos) e validar a consist√™ncia das respostas do modelo.

---


## Como Executar com Docker (recomendado)

### Pr√©-requisitos
- Docker + Docker Compose
- Chave da Groq (env `GROQ_API_KEY`)

### Execu√ß√£o (chat interativo)
A partir da pasta `master-dissertation-code/`:

Garanta que o arquivo `.env` contenha (sem espa√ßos/aspas):

```bash
GROQ_API_KEY=sua_chave_aqui
```

```bash
docker compose run --rm chat
```

- O texto da disserta√ß√£o √© montado como volume em `/data` (ver `docker-compose.yml`).
- O cache do HuggingFace fica em `./.cache/` para evitar baixar o GPT-2 toda vez.

### Executar apontando para outro arquivo de contexto

```bash
docker compose run --rm chat \
  python 01-context-extension-comparison/chat.py \
  --context-file /data/Chapters/002Revision/Revision.tex
```

### Rodar Testes

```bash
docker compose run --rm test
```

Os testes usam mocks e **n√£o precisam de API key real** nem de GPU.

---

## Como Executar (M√≥dulo 01)

### Pr√©-requisitos
- Python 3.8+
- Conta na Groq Cloud (para a API Llama 3)
- Bibliotecas: `groq`, `torch`, `transformers`, `numpy`

### Instala√ß√£o
```bash
pip install -r requirements.txt
```

### Execu√ß√£o
1. Defina sua chave da API Groq:
   ```bash
   export GROQ_API_KEY="sua_chave_aqui"
   ```

2. Navegue at√© o m√≥dulo de compara√ß√£o:
   ```bash
   cd master-dissertation-code/01-context-extension-comparison
   ```

3. Execute o chat:
   ```bash
   python chat.py
   ```

O sistema carregar√° automaticamente o texto base (Cap√≠tulo de Revis√£o da Disserta√ß√£o) e oferecer√° um menu para escolher a estrat√©gia de contexto desejada.
