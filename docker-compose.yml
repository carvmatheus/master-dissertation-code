services:
  chat:
    build: .
    image: master-dissertation-code:latest
    env_file:
      - .env
    environment:
      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
    volumes:
      - ../_local_repo/00-master-thesis-overleaf-help:/data:ro
      - ./.cache:/cache
    stdin_open: true
    tty: true
    command: ["python", "01-context-extension-comparison/chat.py", "--context-file", "/data/Chapters/002Revision/Revision.tex"]

  test:
    build: .
    image: master-dissertation-code:latest
    environment:
      GROQ_API_KEY: fake-key-for-tests
      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
    volumes:
      - ./.cache:/cache
    command: ["pytest", "tests/", "-v", "--tb=short"]

  # ============================================================
  # BENCHMARKS
  # ============================================================

  # Benchmark completo (todos modelos + estratégias)
  benchmark:
    build: .
    image: master-dissertation-code:latest
    env_file:
      - .env
    environment:
      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
    volumes:
      - ./.cache:/cache
      - ./benchmark_results:/app/master-dissertation-code/benchmark_results
    command: ["python", "01-context-extension-comparison/run_benchmarks.py"]

  # Benchmark rápido (menos casos de teste)
  benchmark-quick:
    build: .
    image: master-dissertation-code:latest
    env_file:
      - .env
    environment:
      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
    volumes:
      - ./.cache:/cache
      - ./benchmark_results:/app/master-dissertation-code/benchmark_results
    command: ["python", "01-context-extension-comparison/run_benchmarks.py", "--quick"]

  # Benchmark mock (sem API, para validar estrutura)
  benchmark-mock:
    build: .
    image: master-dissertation-code:latest
    environment:
      GROQ_API_KEY: not-needed-for-mock
      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
    volumes:
      - ./.cache:/cache
      - ./benchmark_results:/app/master-dissertation-code/benchmark_results
    command: ["python", "01-context-extension-comparison/run_benchmarks.py", "--mock-only", "--quick"]

  # ============================================================
  # BENCHMARKS POR MODELO (pré-configurados)
  # ============================================================

  # Llama 3.1 8B (rápido)
  benchmark-llama8b:
    build: .
    image: master-dissertation-code:latest
    env_file:
      - .env
    environment:
      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
    volumes:
      - ./.cache:/cache
      - ./benchmark_results:/app/master-dissertation-code/benchmark_results
    command: >
      python 01-context-extension-comparison/run_benchmarks.py
      --models llama-3.1-8b-instant
      --quick

  # Llama 3.3 70B (mais preciso)
  benchmark-llama70b:
    build: .
    image: master-dissertation-code:latest
    env_file:
      - .env
    environment:
      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
    volumes:
      - ./.cache:/cache
      - ./benchmark_results:/app/master-dissertation-code/benchmark_results
    command: >
      python 01-context-extension-comparison/run_benchmarks.py
      --models llama-3.3-70b-versatile
      --quick

  # ============================================================
  # BENCHMARKS POR TESTE (pré-configurados)
  # ============================================================

  # Apenas Needle-in-a-Haystack
  benchmark-needle:
    build: .
    image: master-dissertation-code:latest
    env_file:
      - .env
    environment:
      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
    volumes:
      - ./.cache:/cache
      - ./benchmark_results:/app/master-dissertation-code/benchmark_results
    command: >
      python 01-context-extension-comparison/run_benchmarks.py
      --benchmarks needle_in_haystack
      --quick

  # Apenas RULER
  benchmark-ruler:
    build: .
    image: master-dissertation-code:latest
    env_file:
      - .env
    environment:
      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
    volumes:
      - ./.cache:/cache
      - ./benchmark_results:/app/master-dissertation-code/benchmark_results
    command: >
      python 01-context-extension-comparison/run_benchmarks.py
      --benchmarks ruler
      --quick

  # Apenas LongBench
  benchmark-longbench:
    build: .
    image: master-dissertation-code:latest
    env_file:
      - .env
    environment:
      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
    volumes:
      - ./.cache:/cache
      - ./benchmark_results:/app/master-dissertation-code/benchmark_results
    command: >
      python 01-context-extension-comparison/run_benchmarks.py
      --benchmarks longbench
      --quick

  # ============================================================
  # BENCHMARK CUSTOMIZÁVEL (base para sobrescrever comando)
  # ============================================================
  
  # Use: docker compose run --rm bench python 01-context-extension-comparison/run_benchmarks.py --models X --strategies Y --benchmarks Z
  bench:
    build: .
    image: master-dissertation-code:latest
    env_file:
      - .env
    environment:
      HF_HOME: /cache/huggingface
      TRANSFORMERS_CACHE: /cache/huggingface/transformers
    volumes:
      - ./.cache:/cache
      - ./benchmark_results:/app/master-dissertation-code/benchmark_results
    working_dir: /app/master-dissertation-code
